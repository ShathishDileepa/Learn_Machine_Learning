{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2df7712",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "In this Notebook we will be discussing, how to process text tobe able to using in NLP models and will be making some NLP models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec5b50b",
   "metadata": {},
   "source": [
    "## .csv VS .tsv\n",
    "\n",
    "* Most of the times in ML we are working with .csv(Comma Seperated Values) files. So for most of the ML task these type of files are okay. But when it comes to NLP it is not good to used .csv files, because we may have instance like where the Text value might have ',' in them. This will mess up extracting the data.\n",
    "\n",
    "* So when we prepare our datasets it is always good to use .tsv(Tab Seperated Values) files. Because it is highly unlikely we will have tabs inside normal text like reviews, comments etc.\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "> In this notebook we will be looking at already labeld set of reviews and try to create a NLP model that can identify a review whether it is negative or positive\n",
    "\n",
    "## Workflow...\n",
    "\n",
    "1. Import the text data\n",
    "2. Clean the data\n",
    "    * Make all letteres lowercase\n",
    "    * Get rid of special characters\n",
    "    * Get rid of any numbers unless they have some significance\n",
    "    * Get rid of words like 'The', 'A', 'An', 'in', 'is', 'am' and 'are' etc. (Because these words does not help to identify any thing)\n",
    "    * Apply stemming (Only take the root word of words) ex: Loved, Loving, Loves -> Love\n",
    "3. Create a Bag of words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8504dff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets import the modules\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# setting a global random seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7f8dec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Now I am getting angry and I want my damn pho.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Honeslty it didn't taste THAT fresh.)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The potatoes were like rubber and you could te...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The fries were great too.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A great touch.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1\n",
       "5     Now I am getting angry and I want my damn pho.      0\n",
       "6              Honeslty it didn't taste THAT fresh.)      0\n",
       "7  The potatoes were like rubber and you could te...      0\n",
       "8                          The fries were great too.      1\n",
       "9                                     A great touch.      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the .tsv file\n",
    "\n",
    "# we can still use the read_csv() method we have to set some additional parameters\n",
    "data = pd.read_csv('data/Natural Language Processing/Restaurant_Reviews.tsv',delimiter='\\t',quoting=3)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47e66316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wow    Loved this place '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning Text Data\n",
    "\n",
    "review ='Wow... Loved this place.'\n",
    "\n",
    "# We wil performe several cleaning process to demeonstrate and use them on the data set within a loop\n",
    "\n",
    "# Import the Python RegEx Module\n",
    "import re\n",
    "\n",
    "# get rid of everything except alphabetical letters and replace them with spaces for avoid making nonsence words\n",
    "review = re.sub('[^a-zA-Z]',' ', review)\n",
    "\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "791857d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wow    loved this place '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn everything into lowercase\n",
    "review = review.lower()\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54b0ff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to install NLTK\n",
    "#!pip install nltk\n",
    "#!python -m nltk.downloader all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e70db40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of words like 'the', 'that', 'is am are' etc. that does not help in identifying process\n",
    "import nltk\n",
    "from nltk.corpus import stopwords # This module contain list of garbage words\n",
    "from nltk.stem import PorterStemmer # This is used for stemming the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29363f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wow', 'loved', 'place']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets get rid of the stop words in the review\n",
    "review = review.split() # this will return a list of words\n",
    "review = [word for word in review if not word in stopwords.words('english')]\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1654578d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wow', 'love', 'place']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets stem all the words\n",
    "\n",
    "stemmer = PorterStemmer() # Create a stemmer object\n",
    "\n",
    "review = [stemmer.stem(word) for word in review]\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0eb441cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can do stemming and getting rid of garbage words in one line as well\n",
    "\n",
    "#review = [stemmer.stem(word) for word in review if not word in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "652c6be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wow love place'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we have to join the words in the list and create a string as the last step\n",
    "review = ' '.join(review)\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2425ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now lets perform this to every value in our data set one by one\n",
    "import nltk\n",
    "from nltk.corpus import stopwords # This module contain list of garbage words\n",
    "from nltk.stem import PorterStemmer # This is used for stemming the words\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "# we have to get a deep copy other wise if something goes south we have to restart the kernal\n",
    "# reviews = data['Review'].values pass a reference\n",
    "reviews = data.iloc[:,0].copy(deep=True)\n",
    "type(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "809cd993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through each review and change them\n",
    "for i in range(len(reviews)):\n",
    "    # turn to lowercase\n",
    "    reviews[i] = reviews[i].lower()\n",
    "    \n",
    "    # Only keep letters\n",
    "    reviews[i] = re.sub('[^a-z]',' ',reviews[i])\n",
    "    \n",
    "    \n",
    "    # Get rid of stop words and do stemming\n",
    "    reviews[i] = reviews[i].split() # this will return a list of words\n",
    "    reviews[i] = [stemmer.stem(word) for word in reviews[i] if not word in stopwords.words('english')]\n",
    "    \n",
    "    # Now we have to join the words\n",
    "    reviews[i] = ' '.join(reviews[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0208fb7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       wow love place\n",
       "1                                           crust good\n",
       "2                                   tasti textur nasti\n",
       "3    stop late may bank holiday rick steve recommen...\n",
       "4                              select menu great price\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now review is ready\n",
    "reviews[:5]\n",
    "# Those dots are not special character, its just to indicate string is long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff7f00e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3959eae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we can update reviews\n",
    "type(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d03d616",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Review'] = reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72275442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wow love place</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crust good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tasti textur nasti</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stop late may bank holiday rick steve recommen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>select menu great price</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                                     wow love place      1\n",
       "1                                         crust good      0\n",
       "2                                 tasti textur nasti      0\n",
       "3  stop late may bank holiday rick steve recommen...      1\n",
       "4                            select menu great price      1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n",
    "# Noooice...!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2118946",
   "metadata": {},
   "source": [
    "## Bag of words \n",
    "\n",
    "* So what is this this is actually kind of a dummy variable matrix.\n",
    "* What's that supposed to mean? It means we will create a matrix containing a column for each word in our  reviews list\n",
    "* And if the word is in our review, column value will be 1 else 0\n",
    "* Thats why I said its kind of like dummy variables (one hot encoder output) for categorical variables\n",
    "* after that we can find the patterns using classification, its just simple as that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7d2923b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bag of words model\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# we have to set max features, because sometimes there maybe words that will not appear in the reviews again ex: 'wow'\n",
    "# So by setting max features CountVectorizer will only keep most important features\n",
    "transformer = CountVectorizer(max_features=1500)\n",
    "X = transformer.fit_transform(reviews).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "949d855f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets look at X\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bc2e2cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can use this in a classification problem\n",
    "\n",
    "y = data['Liked']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c81dff5",
   "metadata": {},
   "source": [
    "* lets create a machine learning model, We can use any classification model, But most commonly used ones for NLP are\n",
    "    * Naive Bayes Model\n",
    "    * Decision Trees Model\n",
    "    * Random Forrest Model\n",
    "\n",
    "We will use Random Forrest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "95d42638",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Split the data into train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "\n",
    "# No need of feature scalling\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=550,)\n",
    "model.fit(X=X_train,y=y_train)\n",
    "\n",
    "# Getting a prediction\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "322edb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lets get a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_true=y_test,y_pred=y_pred)\n",
    "disp =ConfusionMatrixDisplay(cm)\n",
    "disp.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c98fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
